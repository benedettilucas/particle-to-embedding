{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b525bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navms-pdi2/anaconda3/envs/extractors/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from superpoint.models.superpoint_pytorch import SuperPoint\n",
    "from accelerated_features.modules.xfeat import XFeat\n",
    "from accelerated_features.modules.lighterglue import LighterGlue\n",
    "import cv2\n",
    "import numpy as np\n",
    "from utils import generate_random_keypoints, get_descriptors_from_keypoints, cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2443663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from: /home/navms-pdi2/Documentos/lucas-benedetti/01-feature-extraction/accelerated_features/modules/../weights/xfeat.pt\n"
     ]
    }
   ],
   "source": [
    "xfeat = XFeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d871521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_img = Image.open('UFRGS-01-2017.png').convert(\"L\")\n",
    "reference_input = {\"image\": transforms.ToTensor()(reference_img).unsqueeze(0)}\n",
    "num_kpts = 2000\n",
    "feats0 = xfeat.detectAndCompute(reference_input[\"image\"], top_k = num_kpts)[0]\n",
    "feats1 = get_descriptors_from_keypoints(model=xfeat, x=reference_input[\"image\"], feats=feats0, inference=False) # (N, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994ef3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats0['keypoints']:  torch.Size([2000, 2])\n",
      "feats1['keypoints']:  torch.Size([2000, 2])\n",
      "feats0['scores']:  torch.Size([2000])\n",
      "feats1['scores']:  torch.Size([2000])\n",
      "feats0['descriptors']:  torch.Size([2000, 64])\n",
      "feats1['descriptors']:  torch.Size([2000, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"feats0['keypoints']: \",feats0['keypoints'].shape)\n",
    "print(f\"feats1['keypoints']: \",feats1['keypoints'].shape)\n",
    "print(f\"feats0['scores']: \",feats0['scores'].shape)\n",
    "print(f\"feats1['scores']: \",feats1['scores'].shape)\n",
    "print(f\"feats0['descriptors']: \",feats0['descriptors'].shape)\n",
    "print(f\"feats1['descriptors']: \",feats1['descriptors'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f846a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_kpts):\n",
    "    sim = cosine_sim(feats0['descriptors'][i], feats1['descriptors'][i])\n",
    "    #print(f\"[{i}] cos_similarity:{sim})\")\n",
    "    if sim < 0.99:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89bbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_img = Image.open('009-align.jpg').convert(\"L\")\n",
    "scene_input = {\"image\": transforms.ToTensor()(scene_img).unsqueeze(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07c9acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropassion(img):\n",
    "    # Carregar e converter para tons de cinza\n",
    "    reference_img = Image.open(img).convert(\"L\")\n",
    "\n",
    "    # Converter para numpy\n",
    "    img_np = np.array(reference_img)\n",
    "\n",
    "    # Altura atual e nova altura\n",
    "    h, w = img_np.shape\n",
    "    new_h = 421\n",
    "\n",
    "    # Largura proporcional\n",
    "    scale = new_h / h\n",
    "    new_w = int(w * scale)\n",
    "\n",
    "    # Resize proporcional\n",
    "    resized_img = reference_img.resize((new_w, new_h), Image.BICUBIC)\n",
    "    resized_np = np.array(resized_img)\n",
    "\n",
    "    # ---- CROP CENTRAL PARA 421 x 421 ----\n",
    "    target_size = 421\n",
    "\n",
    "    # calcular inÃ­cio e fim do corte horizontal\n",
    "    excess = new_w - target_size\n",
    "    left = excess // 2\n",
    "    right = left + target_size\n",
    "\n",
    "    crop_np = resized_np[:, left:right]\n",
    "    return crop_np\n",
    "crop_np = cropassion('009-align.jpg')\n",
    "scene_input = {\"image\": transforms.ToTensor()(crop_np).unsqueeze(0)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b76d2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_kpts = generate_random_keypoints((4800, 4800), num_keypoints=1, operation=(\"localized\", (2860, 1700), 1000), device=\"cuda\") #operation='random'\n",
    "gt_kpt = torch.tensor([[[2860, 1700]]], device='cuda:0')\n",
    "particles_kpts = torch.cat((gt_kpt, particles_kpts), dim=1)\n",
    "\n",
    "feats0 = {'keypoints': particles_kpts[0]}\n",
    "feats0 = get_descriptors_from_keypoints(model=xfeat, x=reference_input[\"image\"], feats=feats0) # (N, 64)\n",
    "feats0.update({'image_size': (reference_input['image'][0][0].shape[1], reference_input['image'][0][0].shape[0])})\n",
    "\n",
    "feats1 = xfeat.detectAndCompute(scene_input[\"image\"], top_k = 1)[0]\n",
    "#feats1 = xfeat.computeGlobalDescriptor(scene_input[\"image\"], resize_to_receptive=False)[0]\n",
    "feats1.update({'image_size': (reference_input['image'][0][0].shape[1], reference_input['image'][0][0].shape[0])})\n",
    "feats1['descriptors'] = feats1['descriptors'].repeat(particles_kpts.shape[1], 1)\n",
    "feats1['keypoints'] = particles_kpts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26de9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkpts_0, mkpts_1, _, output = xfeat.match_lighterglue(feats0, feats1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8145bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2481.174   734.6561]] [[2860. 1700.]]\n"
     ]
    }
   ],
   "source": [
    "print(mkpts_0, mkpts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "particles_kpts = generate_random_keypoints((4800, 4800), num_keypoints=1, operation=(\"localized\", (2860, 1700), 1000), device=\"cuda\") #operation='random'\n",
    "gt_kpt = torch.tensor([[[2860, 1700]]], device='cuda:0')\n",
    "particles_kpts = torch.cat((gt_kpt, particles_kpts), dim=1)\n",
    "\n",
    "feats1 = xfeat.detectAndCompute(reference_input[\"image\"], top_k = 1)[0]\n",
    "feats1['keypoints'] = gt_kpt[0] #1275 1722\n",
    "#feats1['descriptors'] = feats1['descriptors'].repeat(particles_kpts.shape[1], 1)\n",
    "desc = xfeat.computeGlobalDescriptor(reference_input[\"image\"], resize_to_receptive=False)[0]\n",
    "desc['descriptors'] = desc['descriptors'].repeat(particles_kpts.shape[1], 1)\n",
    "desc['keypoints'] = particles_kpts[0]\n",
    "\n",
    "feats0.update({'image_size': (scene_input['image'][0][0].shape[1], scene_input['image'][0][0].shape[0])})\n",
    "feats1.update({'image_size': (scene_input['image'][0][0].shape[1], scene_input['image'][0][0].shape[0])})\n",
    "desc.update({'image_size': (scene_input['image'][0][0].shape[1], scene_input['image'][0][0].shape[0])})\n",
    "mkpts_0, mkpts_1, _, output = xfeat.match_lighterglue(feats0, desc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extractors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
