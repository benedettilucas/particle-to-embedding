{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b525bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from superpoint.models.superpoint_pytorch import SuperPoint\n",
    "from accelerated_features.modules.xfeat import XFeat\n",
    "from accelerated_features.modules.lighterglue import LighterGlue\n",
    "import cv2\n",
    "import numpy as np\n",
    "from utils import generate_random_keypoints, get_descriptors_from_keypoints, cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2443663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from: /home/navms-pdi2/Documentos/lucas-benedetti/01-feature-extraction/accelerated_features/modules/../weights/xfeat.pt\n"
     ]
    }
   ],
   "source": [
    "xfeat = XFeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d871521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_img = Image.open('UFRGS-01-2017.png').convert(\"L\")\n",
    "reference_input = {\"image\": transforms.ToTensor()(reference_img).unsqueeze(0)}\n",
    "num_kpts = 2000\n",
    "feats0 = xfeat.detectAndCompute(reference_input[\"image\"], top_k = num_kpts)[0]\n",
    "feats1 = get_descriptors_from_keypoints(model=xfeat, x=reference_input[\"image\"], feats=feats0) # (N, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994ef3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats0['keypoints']:  torch.Size([2000, 2])\n",
      "feats1['keypoints']:  torch.Size([2000, 2])\n",
      "feats0['scores']:  torch.Size([2000])\n",
      "feats1['scores']:  torch.Size([2000])\n",
      "feats0['descriptors']:  torch.Size([2000, 64])\n",
      "feats1['descriptors']:  torch.Size([2000, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"feats0['keypoints']: \",feats0['keypoints'].shape)\n",
    "print(f\"feats1['keypoints']: \",feats1['keypoints'].shape)\n",
    "print(f\"feats0['scores']: \",feats0['scores'].shape)\n",
    "print(f\"feats1['scores']: \",feats1['scores'].shape)\n",
    "print(f\"feats0['descriptors']: \",feats0['descriptors'].shape)\n",
    "print(f\"feats1['descriptors']: \",feats1['descriptors'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f846a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_kpts):\n",
    "    sim = cosine_sim(feats0['descriptors'][i], feats1['descriptors'][i])\n",
    "    #print(f\"[{i}] cos_similarity:{sim})\")\n",
    "    if sim < 0.99:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scene_img = Image.open('009-align.jpg').convert(\"L\")\n",
    "scene_input = {\"image\": transforms.ToTensor()(scene_img).unsqueeze(0)}\n",
    "particles_kpts = generate_random_keypoints((4800, 4800), num_keypoints=1, operation=(\"localized\", (2860, 1700), 1000), device=\"cuda\") #operation='random'\n",
    "gt_kpt = torch.tensor([[[2860, 1700]]], device='cuda:0')\n",
    "particles_kpts = torch.cat((gt_kpt, particles_kpts), dim=1)\n",
    "\n",
    "feats1 = xfeat.detectAndCompute(reference_input[\"image\"], top_k = 1)[0]\n",
    "feats1['keypoints'] = gt_kpt[0] #1275 1722\n",
    "#feats1['descriptors'] = feats1['descriptors'].repeat(particles_kpts.shape[1], 1)\n",
    "desc = xfeat.computeGlobalDescriptor(reference_input[\"image\"], resize_to_receptive=False)[0]\n",
    "desc['descriptors'] = desc['descriptors'].repeat(particles_kpts.shape[1], 1)\n",
    "desc['keypoints'] = particles_kpts[0]\n",
    "\n",
    "feats0.update({'image_size': (scene_input['image'][0][0].shape[1], scene_input['image'][0][0].shape[0])})\n",
    "feats1.update({'image_size': (scene_input['image'][0][0].shape[1], scene_input['image'][0][0].shape[0])})\n",
    "desc.update({'image_size': (scene_input['image'][0][0].shape[1], scene_input['image'][0][0].shape[0])})\n",
    "mkpts_0, mkpts_1, _, output = xfeat.match_lighterglue(feats0, desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9964c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extractors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
